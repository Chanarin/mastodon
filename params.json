{"name":"Mastodon","tagline":"A simple next-word prediction engine","body":"# Mastodon\r\n\r\nA simple next-word prediction engine\r\n\r\n## Quick start\r\n\r\n```\r\n# Fetch a sample corpus\r\n$ mkdir data\r\n$ mkdir data/samples\r\n$ curl http://norvig.com/big.txt -o data/samples/big.txt\r\n\r\n# Generate stats using NSP\r\n$ mkdir data/output\r\n$ cd scripts\r\n$ ./generate_stats.sh ../data/samples/big.txt ../data/output/\r\n\r\n# Create binary dictionaries\r\n$ cd ..\r\n$ mkdir dictionaries\r\n$ mkdir dictionaries/test\r\n$ cd python\r\n$ python makedict.py -u ../data/output/unigrams.txt -n ../data/output/ngrams2.ll,..$ /data/output/ngrams3.ll,../data/output/ngrams4.ll -o ../dictionaries/test/big.dict\r\n\r\n# Create binary dictionaries for unit tests\r\n$ python makedict.py -t\r\n$ python unittests.py\r\n$ cd ../cpp\r\n$ make test\r\n```\r\n\r\n## Generating statistics\r\n\r\nTo create a binary dictionary, we need data created from the N-Gram Statistics Package (NSP), available at http://www.d.umn.edu/~tpederse/nsp.html. The script `generate_stats.sh` in the `scripts/` folder serves this purpose.\r\n\r\nA sample corpus can be found at http://norvig.com/big.txt.\r\n\r\n\r\n```\r\n$ curl https://dl.dropbox.com/u/228601/8pen/big.txt -o data/samples/big.txt\r\n```\r\n\r\nWe can generate the desired statistics in the following way:\r\n\r\n```\r\n$ cd scripts\r\n$ ./generate_stats.sh INPUT_FILE OUTPUT_DIR\r\n```\r\n\r\n### Unigrams\r\n\r\nThe script generates a simple word frequency list `unigram.txt` in `OUTPUT_DIR`, in which each line is of the form `weight unigram`. Example output:\r\n\r\n```\r\n79377 the\r\n39997 of\r\n38076 and\r\n28604 to\r\n21780 in\r\n20910 a\r\n...\r\n```\r\n\r\nThe weight is simply the number of occurences of the corresponding word in the corpus.\r\n\r\n### N-grams\r\n\r\nThe script then generates a lists of bi-, tri-, and four-grams (`ngrams2.ll`, `ngrams3.ll`, `ngrams4.ll`, also locaed in `OUTPUT_DIR`) of the form `unigram<>unigram<>...<>rank weight` (we ignore `rank` for now). Example output:\r\n\r\n```\r\nof<>the<>2 25053.6988\r\nin<>the<>6 10335.9606\r\ndid<>not<>8 9798.6723\r\n```\r\n\r\n## Generating dictionaries\r\n\r\nTo generate a binary dictionary using output of the NSP, a script `makedict.py` in the `python/` folder is available. Example usage:\r\n\r\n```\r\n$ python makedict.py -u UNIGRAM_FILE -n BIGRAM_FILE,TRIGRAM_FILE,FOURGRAM_FILE -o OUTPUT_FILE\r\n```\r\n\r\n## Using dictionaries\r\n\r\nImplementations in Python and C++ are currently available for loading a binary dictionary and querying it for:\r\n\r\n* Corrections\r\n* Completions (Python only)\r\n* Next-word predictions\r\n\r\n### Python\r\n\r\nHere is a simple usage in Python:\r\n\r\n```\r\nbindict = BinaryDictionary.from_file('../dictionaries/test/test.dict')\r\nbindict.get_predictions(['hello']) # => [('there',10),('sir',3)]\r\nbindict.get_corrections('yuur')    # => ['your','you','year']\r\nbindict.get_completions('yo', 2)   # => ['you','your']\r\n```\r\n\r\n### C++\r\n\r\nHere is a simple usage in C++:\r\n\r\n```\r\nBinaryDictionary bindict;\r\nbindict.fromFile(\"../dictionaries/test/test.dict\");\r\n\r\nstring phrase[] = {\"how\", \"are\"};\r\nvector<weighted_string> holder;\r\nvector<weighted_string> predictions = bindict.getPredictions(phrase, 2, holder, 4);\r\n\r\nvector<weighted_string> holder;\r\nvector<weighted_string> corrections = bindict.getCorrections(\"you\", holder, 100);\r\n```\r\n\r\nNote that querying for word completions is not yet implemented in C++.\r\n\r\n## Unit tests\r\n\r\nThe unit tests are designed to be used with a simple dictionary, located at `dictionaries/test/test.dict`, and generated using the `-t` option:\r\n\r\n```\r\n$ python makedict.py -t\r\n```\r\n\r\n### Python\r\n\r\nThe Python unit tests use the `unittest` module, and are available in `python/unittests.py`:\r\n\r\n```\r\n$ python unittests.py\r\n```\r\n\r\n### C++\r\n\r\nThe C++ unit tests, located at `cpp/tests/unit/test.cpp`, are based on the `UnitTest++` framework (included). Simply use the provided `Makefile` in the `cpp` folder to run the tests:\r\n\r\n```\r\n$ make test\r\n```\r\n\r\n## Generating statistics\r\n\r\n## License\r\n\r\nMastodon is released under the MIT license. See [LICENSE.md](https://github.com/michaelfester/mastodon/blob/develop/LICENSE.md).","google":"UA-41258693-1","note":"Don't delete this file! It's used internally to help with page regeneration."}